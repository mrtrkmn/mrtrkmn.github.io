<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Setup Highly Available Kubernetes Cluster with HAProxy | mrturkmen</title><meta name=keywords content="kubernetes,docker,pod,HAProxy,cluster,master,node,nginx,worker,ingress"><meta name=description content="Installation of Highly Available Kubernetes Cluster"><meta name=author content="mrturkmen"><link rel=canonical href=https://mrturkmen.com/posts/install-ha-kubernetes-cluster/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://mrturkmen.com/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://mrturkmen.com/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://mrturkmen.com/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://mrturkmen.com/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://mrturkmen.com/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-165248542-1','auto'),ga('send','pageview'))</script><meta property="og:title" content="Setup Highly Available Kubernetes Cluster with HAProxy"><meta property="og:description" content="Installation of Highly Available Kubernetes Cluster"><meta property="og:type" content="article"><meta property="og:url" content="https://mrturkmen.com/posts/install-ha-kubernetes-cluster/"><meta property="og:image" content="https://mrturkmen.com/images/kubernetes/kubernetes-logo.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-07-05T17:43:03+00:00"><meta property="article:modified_time" content="2020-07-05T17:43:03+00:00"><meta property="og:site_name" content="Ahmet Turkmen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://mrturkmen.com/images/kubernetes/kubernetes-logo.png"><meta name=twitter:title content="Setup Highly Available Kubernetes Cluster with HAProxy"><meta name=twitter:description content="Installation of Highly Available Kubernetes Cluster"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://mrturkmen.com/posts/"},{"@type":"ListItem","position":2,"name":"Setup Highly Available Kubernetes Cluster with HAProxy","item":"https://mrturkmen.com/posts/install-ha-kubernetes-cluster/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Setup Highly Available Kubernetes Cluster with HAProxy","name":"Setup Highly Available Kubernetes Cluster with HAProxy","description":"Installation of Highly Available Kubernetes Cluster","keywords":["kubernetes","docker","pod","HAProxy","cluster","master","node","nginx","worker","ingress"],"articleBody":"The main purpose of this blog post a simple walkthrough of setting up Kubernetes cluster with external HAProxy which will be the endpoint where our kubectl client communicates over. Node specifications for this setup is given as shown in the table below. Keep in mind that all of them has access to each other with password and without password. The environment which Kubernetes cluster will stay is running on OpenStack. It means that once a configuration (ssh keys, hosts, and etc) is done for example master 1 then all other nodes could be initialized through snapshot of master 1. To be able to setup such a Kubernetes cluster easily, I will be using KubeSpray which is a repository where it has all required configuration and playbooks for setting up necessary cluster.\n Node Specification Prerequisites General Overview KubeSpray Configuration External Load Balancer Setup (HAProxy) Setup KubeSpray Configuration  The intention of this walkthrough is that setting up your own Kubernetes cluster in your own servers, this post is not very useful for people who are already using cloud provider solutions.(Kubernetes cluster as a service). You can checkout following resources listed below : (few of them :) )\nCloud Providers Solutions:\n Azure Kubernetes Service - AKS Google Kubernetes Engine - GKE Managed Kubernetes on DigitalOcean Kubernetes on AWS  Node Specification Kubernetes cluster will be setup on following nodes in the table below, note that HAProxy will run on another node and all ansible playbooks and setting up Kubernetes cluster will be managed through HAProxy. Keep in mind that all nodes + HAProxy is under same subnet internally which means that we will only one external IP address where HAProxy use and kubectl clients communicate. All instances are running on ubuntu_18.04, it means that the instructions and steps may not work with another system.\nPrerequisites  Nodes Requirements of KubeSpray Setting up SSH Key Across Nodes Getting snapshot ( -it is optional -) Setting up login with password  General Overview The following sketch is general overview of how Kubernetes cluster will look like at the end of this walkthrough, the figure is super overviewed version of cluster.\nIn given figure above, nodes do not have any external IP adress however, including HAProxy, all of them in same subnet, only HAProxy has external IP address which will be reachable by kubectl clients.\nBefore moving installation step of Kubernetes cluster, we need to setup a sample master node (instance) with predefined configuration. Since we will have only one server which is open to outside world, we need to make sure that there is a connection between HAProxy and sample master node. I am currently calling it sample master node, it is because, preliminary configurations such as authentication with password, disabled swap area and ssh keys will be all configured. This sample master node should be started and accesible over HAProxy, which means that in order to access to sample master node, I should do following;\n SSH to HAProxy using SSH key (Password Login disabled) like ssh -i ~/.ssh/id_rsa @ Copy SSH Key to HAProxy, which let you in to sample master node Then SSH to sample master node with same approach. (ssh ~/.ssh/masternode.pem @  After you are inside sample master node, now, some configurations and setting should be done. Afterwards, we can initialize other five nodes from snapshot of configured sample master node.\nSteps:\n Enable Password Login if not enabled already.  $ echo \"PermitRootLogin yes\"  /etc/ssh/sshd_config $ sed -i -E 's/PasswordAuthentication no/PasswordAuthentication yes/g' /etc/ssh/sshd_config  Specify Password for ROOT  $ sudo su $ passwd Given commands will ask new unix password for root user. Define the password and do not forget or lose it. Since we will gonna use snapshot of this configured machine, all settings will be same, I did like that to shortcut the process.\n Disable swap area (RUN ALL COMMANDS AS ROOT)  $ swapoff -a Afterwards, exit from sample master node, create snapshot of that node (it is called volume snapshot in OpenStack), once you have successfully created snaphot, all five other nodes should be initialized from snapshot of this sample master node. This way, there is no need to repeat same steps described above.\nIn case of not having possibility to create snapshot follow given steps (if and if only, you could NOT create snapshot and initialize other five nodes from the snapshot)\n  Create all nodes (workers and masters)\n  Enable SSH connection to all nodes from HAPRoxy server.\n  From HAProxy server, execute following steps. (-Make sure that you have configured SSH connection with ROOT priviledges and have access to all nodes from HAProxy node -)\nOnce you are sure that you have SSH access to all nodes from HAProxy through SSH, implement following steps.\n Install parallel-ssh (-to run a command in parallel on nodes-) (run with ROOT priviledges)  $ apt-get update \u0026\u0026 apt-get install -y pssh  Install HAProxy (as ROOT priviledges)  $ apt-get install -y haproxy  Modify /etc/hosts (-For easy communication through nodes-)  Append worker and master node IPs to /etc/hosts file\n$ vim /etc/hosts 10.0.128.156 worker3 10.0.128.137 worker2 10.0.128.81 worker1 10.0.128.184 master3 10.0.128.171 master2 10.0.128.149 master1  Create nodes text file on home directory  $ cat nodes worker3 worker2 worker1 master3 master2 master1 Since IP addresses of them defined in /etc/hosts file, system can now recognize and connect IPs of them through just by name\n Generate and Copy SSH Key to all nodes (Required for easy communication)  If there is already a SSH key (like in ~/.ssh/id_rsa), you can use it as well.If not, you can do following step\n$ ssh-keygen # will prompt passphrase, you can leave empty , NOTE THAT IF YOU DO NOT HAVE SSH KEY, GENERATE IT. $ for i in $(cat nodes); ssh-copy-id $i; done The for loop given as second command will copy ssh key to all nodes, then accesing any node without password will be flawless.Like given command below;\n$ ssh master1 # in defualt uses same username with terminal session  Disable swap area on all nodes (Note that if you are using snapshot method, no need to do this step)  $ parallel-ssh -h nodes -i \"swapoff -a\" Parallel SSH tool is handy to complete tasks in parallel for multiple hosts.\nKubeSpray Configuration KubeSpray is a repository to setup Kubernetes clusters with predefined configuration settings using Ansible playbooks. The usage of KubeSpray is pretty straightforward, as default settings, KubeSpray is using internal load balancers in each worker node, which means that when you setup a Kubernetes cluster using default values of KubeSpray, you will have following arch overview.\nHowever, in this guide, external load balancer approach will be used to setup cluster, if you wish to leave everything as default with KubeSpray, you can skip this External Load Balancer Setup part.\nExternal Load Balancer Setup (HAProxy) Modify configuration file of HAProxy to enable external LoadBalancer, copy this following configuration and append to /etc/haproxy/haproxy.cfg. (end of file)\nlisten kubernetes-apiserver-https bind :8383 mode tcp option log-health-checks timeout client 3h timeout server 3h server master1 :6443 check check-ssl verify none inter 10000 server master2 :6443 check check-ssl verify none inter 10000 server master3 :6443 check check-ssl verify none inter 10000 balance roundrobin Balance algorithm is roundrobin however you can change it from list of available balance algorithms provided by HAProxy.\nOnce it is done, save and restart HAProxy service.\n$ systemctl restart haproxy Setup KubeSpray Configuration Since external load balancer will be used, there is few things to be done to change default values in KubeSpray. Following steps will be done on HAProxy node.\n Clone the project and prepare environment  $ git clone https://github.com/kubernetes-sigs/kubespray $ apt-get install -y python3-pip # install pip3 if not installed $ cd kubespray  Follow the guide on KubeSpray README.md file  Following instructions taken from KubeSpray README.md\n# Install dependencies from ``requirements.txt`` sudo pip3 install -r requirements.txt # Copy ``inventory/sample`` as ``inventory/mycluster`` cp -rfp inventory/sample inventory/mycluster # Update Ansible inventory file with inventory builder declare -a IPS=(10.0.128.149 10.0.128.171 10.0.128.184 10.0.128.81 10.0.128.137 10.0.128.156) CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]}  Modify generate hosts YAML file  When you check inventory/mycluster/hosts.yaml file, you will notice that it created two master nodes, which we require three, add missing one properly to that list as shown below.\nall: hosts: master1: ansible_host: 10.0.128.149 ip: 10.0.128.149 access_ip: 10.0.128.149 master2: ansible_host: 10.0.128.171 ip: 10.0.128.171 access_ip: 10.0.128.171 master3: ansible_host: 10.0.128.184 ip: 10.0.128.184 access_ip: 10.0.128.184 worker1: ansible_host: 10.0.128.81 ip: 10.0.128.81 access_ip: 10.0.128.81 worker2: ansible_host: 10.0.128.137 ip: 10.0.128.137 access_ip: 10.0.128.137 worker3: ansible_host: 10.0.128.156 ip: 10.0.128.156 access_ip: 10.0.128.156 children: kube-master: hosts: master1: master2: master3: kube-node: hosts: master1: master2: master3: worker1: worker2: worker3: etcd: hosts: master1: master2: master3: k8s-cluster: children: kube-master: kube-node: calico-rr: hosts: {} Once it is done, the other thing which should be modified to use external load balancer HAProxy, is all.yaml file located under inventory/mycluster/group_vars/all/.\nall.yml is general configuration file which specifies main configurations of your cluster, it uses Nginx load balancer by default which means that each worker node has its own local nginx load balancer as given second figure above. If not specified anything else.\n Disable default load balancer  $ vim inventory/mycluster/group_vars/all/all.yml loadbalancer_apiserver_localhost: false  Add external load balancer HAProxy.  $ vim inventory/mycluster/group_vars/all/all.yml ## External LB example config apiserver_loadbalancer_domain_name: \"\" loadbalancer_apiserver: address: 10.0.128.193 port: 8383  Initialize cluster deployment  # under kubespray/ directoy  $ ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml It will take around 10-15 minutes which depens on your cluster and if everything goes well, at the end of deployment through Ansible you will not face with any problem. If so, you can test it by SSH to master node and try kubectl cluster-info.\n$ kubectl cluster-info Kubernetes master is running at ..... To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. It means that Kubernetes cluster with three master and three worker nodes available to use.\nNote that the default configuration of cluster could be changed more however before attempting to change default configuration, make sure that you did correct research on what to change on KubeSpray default settings. Otherwise, there might be problems regarding to customized configuration settings.\nFor more information stay updated and watch KubeSpray regarding to issues, pitfalls and more.\nLast step for this post is creating kubectl configuration for your personal/work computer to access the cluster. Install kubectl on your environment. Afterwards copy configuration from master node to your ~/.kube/ as config.\nSince we have only one endpoint, configuration file should be copied to HAProxy Server then your computer, through rsync or scp\n On HAProxy Server  $ scp root@master1:/etc/kubernetes/admin.conf config # will copy admin.conf as config  $ cp config /home/ubuntu/ # copy to a user home dir $ chown ubuntu:ubuntu /home/ubuntu/config # change owner of the file   On your personal/work computer  $ scp -i ~/.ssh/haproxy.pem ubuntu@:/home/ubuntu/config ~/.kube/ Now, you should be able to get and dump your cluster information as in master nodes.\n$ kubectl cluster-info Kubernetes master is running at ..... To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. There are lots of configurations and different settings regarding to Kubernetes cluster environment and generally using Cloud Provider solutions are less painful or painless. However, sometimes it is less costly to setup your own environment and having full access to anything could be better for learning under the hood things or creating highly customized environments. It really depends on your situation therefore it is up to you to go and setup your own Kubernetes cluster or use it as service from cloud providers.\nBy the way, thanks for giving time to checkout the post ðŸ˜‰\n","wordCount":"1898","inLanguage":"en","image":"https://mrturkmen.com/images/kubernetes/kubernetes-logo.png","datePublished":"2020-07-05T17:43:03Z","dateModified":"2020-07-05T17:43:03Z","author":{"@type":"Person","name":"mrturkmen"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://mrturkmen.com/posts/install-ha-kubernetes-cluster/"},"publisher":{"@type":"Organization","name":"mrturkmen","logo":{"@type":"ImageObject","url":"https://mrturkmen.com/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><header class=header><nav class=nav><div class=logo><a href=https://mrturkmen.com/ accesskey=h title="Home (Alt + H)">Home</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://mrturkmen.com/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://mrturkmen.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://mrturkmen.com/>Home</a>&nbsp;Â»&nbsp;<a href=https://mrturkmen.com/posts/>Posts</a></div><h1 class=post-title>Setup Highly Available Kubernetes Cluster with HAProxy</h1><div class=post-description>Installation of Highly Available Kubernetes Cluster</div><div class=post-meta><span title="2020-07-05 17:43:03 +0000 UTC">July 5, 2020</span>&nbsp;Â·&nbsp;9 min&nbsp;Â·&nbsp;mrturkmen&nbsp;|&nbsp;<a href=https://github.com/mrtrkmn/mrtrkmn.github.io/tree/master/content/posts/install-ha-kubernetes-cluster.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=lazy src=https://mrturkmen.com/images/kubernetes/kubernetes-logo.png alt></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#node-specification aria-label="Node Specification">Node Specification</a></li><li><a href=#prerequisites aria-label=Prerequisites>Prerequisites</a></li><li><a href=#general-overview aria-label="General Overview">General Overview</a></li><li><a href=#kubespray-configuration aria-label="KubeSpray Configuration">KubeSpray Configuration</a></li><li><a href=#external-load-balancer-setup-haproxy aria-label="External Load Balancer Setup (HAProxy)">External Load Balancer Setup (HAProxy)</a></li><li><a href=#setup-kubespray-configuration aria-label="Setup KubeSpray Configuration">Setup KubeSpray Configuration</a></li></ul></div></details></div><div class=post-content><p>The main purpose of this blog post a simple walkthrough of setting up Kubernetes cluster with external <a href=http://www.haproxy.org/>HAProxy</a> which will be the endpoint where our <code>kubectl</code> client communicates over.
Node specifications for this setup is given as shown in the table below. Keep in mind that all of them has access to each other with password and without password. The environment which Kubernetes cluster will stay is running on OpenStack. It means that once a configuration (ssh keys, hosts, and etc) is done for example master 1 then all other nodes could be initialized through snapshot of master 1. To be able to setup such a Kubernetes cluster easily, I will be using <a href=https://github.com/kubernetes-sigs/kubespray>KubeSpray</a> which is a repository where it has all required configuration and playbooks for setting up necessary cluster.</p><ul><li><a href=#node-specification>Node Specification</a></li><li><a href=#prerequisites>Prerequisites</a></li><li><a href=#general-overview>General Overview</a></li><li><a href=#kubespray-configuration>KubeSpray Configuration</a></li><li><a href=#external-load-balancer-setup-haproxy>External Load Balancer Setup (HAProxy)</a></li><li><a href=#setup-kubespray-configuration>Setup KubeSpray Configuration</a></li></ul><p>The intention of this walkthrough is that setting up your own Kubernetes cluster in your own servers, this post is not very useful for people who are already using cloud provider solutions.(Kubernetes cluster as a service). You can checkout following resources listed below : (few of them :) )</p><p>Cloud Providers Solutions:</p><ul><li><a href=https://azure.microsoft.com/en-us/services/kubernetes-service/>Azure Kubernetes Service - AKS</a></li><li><a href=https://cloud.google.com/kubernetes-engine>Google Kubernetes Engine - GKE</a></li><li><a href=https://www.digitalocean.com/products/kubernetes/>Managed Kubernetes on DigitalOcean</a></li><li><a href=https://aws.amazon.com/kubernetes/>Kubernetes on AWS</a></li></ul><h1 id=node-specification>Node Specification<a hidden class=anchor aria-hidden=true href=#node-specification>#</a></h1><p>Kubernetes cluster will be setup on following nodes in the table below, note that HAProxy will run on another node and all ansible playbooks and setting up Kubernetes cluster will be managed through HAProxy. Keep in mind that all nodes + HAProxy is under same subnet internally which means that we will only one external IP address where HAProxy use and <code>kubectl</code> clients communicate. All instances are running on ubuntu_18.04, it means that the instructions and steps may not work with another system.</p><h1 id=prerequisites>Prerequisites<a hidden class=anchor aria-hidden=true href=#prerequisites>#</a></h1><ul><li>Nodes</li><li><a href=https://github.com/kubernetes-sigs/kubespray/blob/master/requirements.txt>Requirements</a> of KubeSpray</li><li>Setting up SSH Key Across Nodes</li><li>Getting snapshot ( -it is optional -)</li><li>Setting up login with password</li></ul><h1 id=general-overview>General Overview<a hidden class=anchor aria-hidden=true href=#general-overview>#</a></h1><p>The following sketch is general overview of how Kubernetes cluster will look like at the end of this walkthrough, the figure is super overviewed version of cluster.</p><p><img loading=lazy src=../../images/kubernetes/overview-kube-cluster.png alt="General Overview Cluster"></p><p>In given figure above, nodes do not have any external IP adress however, including HAProxy, all of them in same subnet, only HAProxy has external IP address which will be reachable by <code>kubectl</code> clients.</p><p>Before moving installation step of Kubernetes cluster, we need to setup a sample master node (instance) with predefined configuration. Since we will have only one server which is open to outside world, we need to make sure that there is a connection between HAProxy and sample master node. I am currently calling it sample master node, it is because, preliminary configurations such as authentication with password, disabled swap area and ssh keys will be all configured. This sample master node should be started and accesible over HAProxy, which means that in order to access to sample master node, I should do following;</p><ul><li>SSH to HAProxy using SSH key (<strong>Password Login disabled</strong>) like <code>ssh -i ~/.ssh/id_rsa &lt;username>@&lt;ha-proxy-external-ip></code></li><li>Copy SSH Key to HAProxy, which let you in to sample master node</li><li>Then SSH to sample master node with same approach. (<code>ssh ~/.ssh/masternode.pem &lt;username>@&lt;master-node-ip></code></li></ul><p>After you are inside sample master node, now, some configurations and setting should be done. Afterwards, we can initialize other five nodes from snapshot of configured sample master node.</p><p>Steps:</p><ul><li><strong>Enable Password Login if not enabled already.</strong></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ echo <span style=color:#e6db74>&#34;PermitRootLogin yes&#34;</span> &gt;&gt; /etc/ssh/sshd_config
$ sed -i -E <span style=color:#e6db74>&#39;s/PasswordAuthentication no/PasswordAuthentication yes/g&#39;</span> /etc/ssh/sshd_config
</code></pre></div><ul><li><strong>Specify Password for ROOT</strong></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ sudo su 
$ passwd 
</code></pre></div><p>Given commands will ask new unix password for root user. Define the password and do not forget or lose it. Since we will gonna use snapshot of this configured machine, all settings will be same, I did like that to shortcut the process.</p><ul><li><strong>Disable swap area (RUN ALL COMMANDS AS ROOT)</strong></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ swapoff -a
</code></pre></div><p>Afterwards, exit from sample master node, create snapshot of that node (it is called volume snapshot in OpenStack), once you have successfully created snaphot, all five other nodes should be initialized from snapshot of this sample master node. This way, there is no need to repeat same steps described above.</p><p>In case of not having possibility to create snapshot follow given steps (if and if only, you could NOT create snapshot and initialize other five nodes from the snapshot)</p><ul><li><p>Create all nodes (workers and masters)</p></li><li><p>Enable SSH connection to all nodes from HAPRoxy server.</p></li></ul><p>From HAProxy server, execute following steps. (-Make sure that you have configured SSH connection with ROOT priviledges and have access to all nodes from HAProxy node -)</p><p>Once you are sure that you have SSH access to all nodes from HAProxy through SSH, implement following steps.</p><ul><li><strong>Install parallel-ssh (-to run a command in parallel on nodes-) (run with ROOT priviledges)</strong></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ apt-get update <span style=color:#f92672>&amp;&amp;</span> apt-get install -y pssh
</code></pre></div><ul><li><strong>Install HAProxy (as ROOT priviledges)</strong></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ apt-get install -y haproxy 
</code></pre></div><ul><li><strong>Modify <code>/etc/hosts</code> (-For easy communication through nodes-)</strong></li></ul><p><em>Append worker and master node IPs to <code>/etc/hosts</code> file</em></p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ vim /etc/hosts 
10.0.128.156 worker3
10.0.128.137 worker2
10.0.128.81  worker1
10.0.128.184 master3
10.0.128.171 master2
10.0.128.149 master1
</code></pre></div><ul><li><strong>Create <code>nodes</code> text file on home directory</strong></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ cat nodes 
worker3
worker2
worker1
master3
master2
master1
</code></pre></div><p><em>Since IP addresses of them defined in <code>/etc/hosts</code> file, system can now recognize and connect IPs of them through just by name</em></p><ul><li><strong>Generate and Copy SSH Key to all nodes</strong> (Required for easy communication)</li></ul><p>If there is already a SSH key (like in <code>~/.ssh/id_rsa</code>), you can use it as well.If not, you can do following step</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ ssh-keygen  <span style=color:#75715e># will prompt passphrase, you can leave empty , NOTE THAT IF YOU DO NOT HAVE SSH KEY, GENERATE IT.</span>

$ <span style=color:#66d9ef>for</span> i in <span style=color:#66d9ef>$(</span>cat nodes<span style=color:#66d9ef>)</span>; ssh-copy-id $i; <span style=color:#66d9ef>done</span>  
</code></pre></div><p>The for loop given as second command will copy ssh key to all nodes, then accesing any node without password will be flawless.Like given command below;</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$  ssh master1  <span style=color:#75715e># in defualt uses same username with terminal session</span>
</code></pre></div><ul><li><strong>Disable swap area on all nodes (Note that if you are using snapshot method, no need to do this step)</strong></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ parallel-ssh -h nodes -i <span style=color:#e6db74>&#34;swapoff -a&#34;</span>
</code></pre></div><p>Parallel SSH tool is handy to complete tasks in parallel for multiple hosts.</p><h1 id=kubespray-configuration>KubeSpray Configuration<a hidden class=anchor aria-hidden=true href=#kubespray-configuration>#</a></h1><p>KubeSpray is a repository to setup Kubernetes clusters with predefined configuration settings using Ansible playbooks. The usage of KubeSpray is pretty straightforward, as default settings, KubeSpray is using internal load balancers in each worker node, which means that when you setup a Kubernetes cluster using default values of KubeSpray, you will have following arch overview.</p><p><img loading=lazy src=../../images/kubernetes/overview-kube-cluster-default.png alt="Default Kubernetes Arch with KubeSpray Setup"></p><p>However, in this guide, external load balancer approach will be used to setup cluster, if you wish to leave everything as default with KubeSpray, you can skip this <a href=#external-load-balancer-setup>External Load Balancer Setup</a> part.</p><h1 id=external-load-balancer-setup-haproxy>External Load Balancer Setup (HAProxy)<a hidden class=anchor aria-hidden=true href=#external-load-balancer-setup-haproxy>#</a></h1><p>Modify configuration file of HAProxy to enable external LoadBalancer, copy this following configuration and append to <code>/etc/haproxy/haproxy.cfg</code>. (end of file)</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cfg data-lang=cfg><span style=color:#a6e22e>listen kubernetes-apiserver-https</span>
  <span style=color:#a6e22e>bind &lt;your-haproxy-internal-ip&gt;:8383</span>
  <span style=color:#a6e22e>mode tcp</span>
  <span style=color:#a6e22e>option log-health-checks</span>
  <span style=color:#a6e22e>timeout client 3h</span>
  <span style=color:#a6e22e>timeout server 3h</span>
  <span style=color:#a6e22e>server master1 &lt;your-master1-ip&gt;:6443 check check-ssl verify none inter 10000</span>
  <span style=color:#a6e22e>server master2 &lt;your-master2-ip&gt;:6443 check check-ssl verify none inter 10000</span>
  <span style=color:#a6e22e>server master3 &lt;your-master3-ip&gt;:6443 check check-ssl verify none inter 10000</span>
  <span style=color:#a6e22e>balance roundrobin</span>

</code></pre></div><p>Balance algorithm is <code>roundrobin</code> however you can change it from list of available <a href=https://cbonte.github.io/haproxy-dconv/configuration-1.4.html#4.2-balance>balance algorithms</a> provided by HAProxy.</p><p>Once it is done, save and restart HAProxy service.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ systemctl restart haproxy
</code></pre></div><h1 id=setup-kubespray-configuration>Setup KubeSpray Configuration<a hidden class=anchor aria-hidden=true href=#setup-kubespray-configuration>#</a></h1><p>Since external load balancer will be used, there is few things to be done to change default values in KubeSpray. Following steps will be done on HAProxy node.</p><ul><li><strong>Clone the project and prepare environment</strong></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>
$ git clone https://github.com/kubernetes-sigs/kubespray
$ apt-get install -y python3-pip <span style=color:#75715e># install pip3 if not installed</span>
$ cd kubespray
</code></pre></div><ul><li><strong>Follow the guide on KubeSpray README.md file</strong></li></ul><p>Following instructions taken from <a href=https://github.com/kubernetes-sigs/kubespray>KubeSpray README.md</a></p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#75715e># Install dependencies from ``requirements.txt``</span>
sudo pip3 install -r requirements.txt
<span style=color:#75715e># Copy ``inventory/sample`` as ``inventory/mycluster``</span>
cp -rfp inventory/sample inventory/mycluster
<span style=color:#75715e># Update Ansible inventory file with inventory builder</span>
declare -a IPS<span style=color:#f92672>=(</span>10.0.128.149 10.0.128.171 10.0.128.184 10.0.128.81 10.0.128.137 10.0.128.156<span style=color:#f92672>)</span>
CONFIG_FILE<span style=color:#f92672>=</span>inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py <span style=color:#e6db74>${</span>IPS[@]<span style=color:#e6db74>}</span>
</code></pre></div><ul><li><strong>Modify generate hosts YAML file</strong></li></ul><p>When you check <code>inventory/mycluster/hosts.yaml</code> file, you will notice that it created two master nodes, which we require three, add missing one properly to that list as shown below.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#f92672>all</span>:
  <span style=color:#f92672>hosts</span>:
    <span style=color:#f92672>master1</span>:
      <span style=color:#f92672>ansible_host</span>: <span style=color:#ae81ff>10.0.128.149</span>
      <span style=color:#f92672>ip</span>: <span style=color:#ae81ff>10.0.128.149</span>
      <span style=color:#f92672>access_ip</span>: <span style=color:#ae81ff>10.0.128.149</span>
    <span style=color:#f92672>master2</span>:
      <span style=color:#f92672>ansible_host</span>: <span style=color:#ae81ff>10.0.128.171</span>
      <span style=color:#f92672>ip</span>: <span style=color:#ae81ff>10.0.128.171</span>
      <span style=color:#f92672>access_ip</span>: <span style=color:#ae81ff>10.0.128.171</span>
    <span style=color:#f92672>master3</span>:
      <span style=color:#f92672>ansible_host</span>: <span style=color:#ae81ff>10.0.128.184</span>
      <span style=color:#f92672>ip</span>: <span style=color:#ae81ff>10.0.128.184</span>
      <span style=color:#f92672>access_ip</span>: <span style=color:#ae81ff>10.0.128.184</span>
    <span style=color:#f92672>worker1</span>:
      <span style=color:#f92672>ansible_host</span>: <span style=color:#ae81ff>10.0.128.81</span>
      <span style=color:#f92672>ip</span>: <span style=color:#ae81ff>10.0.128.81</span>
      <span style=color:#f92672>access_ip</span>: <span style=color:#ae81ff>10.0.128.81</span>
    <span style=color:#f92672>worker2</span>:
      <span style=color:#f92672>ansible_host</span>: <span style=color:#ae81ff>10.0.128.137</span>
      <span style=color:#f92672>ip</span>: <span style=color:#ae81ff>10.0.128.137</span>
      <span style=color:#f92672>access_ip</span>: <span style=color:#ae81ff>10.0.128.137</span>
    <span style=color:#f92672>worker3</span>:
      <span style=color:#f92672>ansible_host</span>: <span style=color:#ae81ff>10.0.128.156</span>
      <span style=color:#f92672>ip</span>: <span style=color:#ae81ff>10.0.128.156</span>
      <span style=color:#f92672>access_ip</span>: <span style=color:#ae81ff>10.0.128.156</span>
  <span style=color:#f92672>children</span>:
    <span style=color:#f92672>kube-master</span>:
      <span style=color:#f92672>hosts</span>:
        <span style=color:#f92672>master1</span>:
        <span style=color:#f92672>master2</span>:
        <span style=color:#f92672>master3</span>:
    <span style=color:#f92672>kube-node</span>:
      <span style=color:#f92672>hosts</span>:
        <span style=color:#f92672>master1</span>:
        <span style=color:#f92672>master2</span>:
        <span style=color:#f92672>master3</span>:
        <span style=color:#f92672>worker1</span>:
        <span style=color:#f92672>worker2</span>:
        <span style=color:#f92672>worker3</span>:
    <span style=color:#f92672>etcd</span>:
      <span style=color:#f92672>hosts</span>:
        <span style=color:#f92672>master1</span>:
        <span style=color:#f92672>master2</span>:
        <span style=color:#f92672>master3</span>:
    <span style=color:#f92672>k8s-cluster</span>:
      <span style=color:#f92672>children</span>:
        <span style=color:#f92672>kube-master</span>:
        <span style=color:#f92672>kube-node</span>:
    <span style=color:#f92672>calico-rr</span>:
      <span style=color:#f92672>hosts</span>: {}
</code></pre></div><p>Once it is done, the other thing which should be modified to use external load balancer HAProxy, is <code>all.yaml</code> file located under <code>inventory/mycluster/group_vars/all/</code>.</p><p><code>all.yml</code> is general configuration file which specifies main configurations of your cluster, it uses Nginx load balancer by default which means that each worker node has its own local nginx load balancer as given second figure above. If not specified anything else.</p><ul><li><strong>Disable default load balancer</strong></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ vim inventory/mycluster/group_vars/all/all.yml
loadbalancer_apiserver_localhost: false
</code></pre></div><ul><li><strong>Add external load balancer HAProxy.</strong></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ vim inventory/mycluster/group_vars/all/all.yml
<span style=color:#75715e>## External LB example config</span>
apiserver_loadbalancer_domain_name: <span style=color:#e6db74>&#34;&lt;domain-name-of-lb&gt;&#34;</span>
loadbalancer_apiserver:
  address: 10.0.128.193
  port: <span style=color:#ae81ff>8383</span>
</code></pre></div><ul><li><strong>Initialize cluster deployment</strong></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#75715e># under kubespray/ directoy </span>
$ ansible-playbook -i inventory/mycluster/hosts.yaml  --become --become-user<span style=color:#f92672>=</span>root cluster.yml
</code></pre></div><p>It will take around 10-15 minutes which depens on your cluster and if everything goes well, at the end of deployment through Ansible you will not face with any problem. If so, you can test it by SSH to <code>master</code> node and try <code>kubectl cluster-info</code>.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ kubectl cluster-info
Kubernetes master is running at .....

To further debug and diagnose cluster problems, use <span style=color:#e6db74>&#39;kubectl cluster-info dump&#39;</span>.
</code></pre></div><p>It means that Kubernetes cluster with three master and three worker nodes available to use.</p><p>Note that the default configuration of cluster could be changed more however before attempting to change default configuration, make sure that you did correct research on what to change on KubeSpray default settings. Otherwise, there might be problems regarding to customized configuration settings.</p><p>For more information stay updated and watch <a href=https://github.com/kubernetes-sigs/kubespray>KubeSpray</a> regarding to issues, pitfalls and more.</p><p>Last step for this post is creating <code>kubectl</code> configuration for your personal/work computer to access the cluster. <a href=https://kubernetes.io/docs/tasks/tools/install-kubectl/>Install kubectl</a> on your environment. Afterwards copy configuration from master node to your <code>~/.kube/</code> as <code>config</code>.</p><p>Since we have only one endpoint, configuration file should be copied to HAProxy Server then your computer, through <code>rsync</code> or <code>scp</code></p><ul><li><strong>On HAProxy Server</strong></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ scp root@master1:/etc/kubernetes/admin.conf config  <span style=color:#75715e># will copy admin.conf as config </span>
$ cp config /home/ubuntu/    <span style=color:#75715e># copy to a user home dir</span>
$ chown ubuntu:ubuntu /home/ubuntu/config    <span style=color:#75715e># change owner of the file </span>
</code></pre></div><ul><li><strong>On your personal/work computer</strong></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ scp -i ~/.ssh/haproxy.pem ubuntu@&lt;ha-proxy-ip&gt;:/home/ubuntu/config  ~/.kube/
</code></pre></div><p>Now, you should be able to get and dump your cluster information as in master nodes.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ kubectl cluster-info
Kubernetes master is running at .....

To further debug and diagnose cluster problems, use <span style=color:#e6db74>&#39;kubectl cluster-info dump&#39;</span>.
</code></pre></div><p>There are lots of configurations and different settings regarding to Kubernetes cluster environment and generally using Cloud Provider solutions are less painful or painless. However, sometimes it is less costly to setup your own environment and having full access to anything could be better for learning under the hood things or creating highly customized environments. It really depends on your situation therefore it is up to you to go and setup your own Kubernetes cluster or use it as service from cloud providers.</p><p>By the way, thanks for giving time to checkout the post ðŸ˜‰</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://mrturkmen.com/tags/kubernetes/>kubernetes</a></li><li><a href=https://mrturkmen.com/tags/docker/>docker</a></li><li><a href=https://mrturkmen.com/tags/pod/>pod</a></li><li><a href=https://mrturkmen.com/tags/haproxy/>HAProxy</a></li><li><a href=https://mrturkmen.com/tags/cluster/>cluster</a></li><li><a href=https://mrturkmen.com/tags/master/>master</a></li><li><a href=https://mrturkmen.com/tags/node/>node</a></li><li><a href=https://mrturkmen.com/tags/nginx/>nginx</a></li><li><a href=https://mrturkmen.com/tags/worker/>worker</a></li><li><a href=https://mrturkmen.com/tags/ingress/>ingress</a></li></ul><nav class=paginav><a class=prev href=https://mrturkmen.com/posts/setup-ingress-controller/><span class=title>Â« Prev Page</span><br><span>NGINX Ingress Controller with HAProxy for k8s cluster</span></a>
<a class=next href=https://mrturkmen.com/posts/vpn-kuralim/><span class=title>Next Page Â»</span><br><span>Kendimize Ã¶zel VPN kurulumu</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Setup Highly Available Kubernetes Cluster with HAProxy on twitter" href="https://twitter.com/intent/tweet/?text=Setup%20Highly%20Available%20Kubernetes%20Cluster%20with%20HAProxy&url=https%3a%2f%2fmrturkmen.com%2fposts%2finstall-ha-kubernetes-cluster%2f&hashtags=kubernetes%2cdocker%2cpod%2cHAProxy%2ccluster%2cmaster%2cnode%2cnginx%2cworker%2cingress"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Setup Highly Available Kubernetes Cluster with HAProxy on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fmrturkmen.com%2fposts%2finstall-ha-kubernetes-cluster%2f&title=Setup%20Highly%20Available%20Kubernetes%20Cluster%20with%20HAProxy&summary=Setup%20Highly%20Available%20Kubernetes%20Cluster%20with%20HAProxy&source=https%3a%2f%2fmrturkmen.com%2fposts%2finstall-ha-kubernetes-cluster%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Setup Highly Available Kubernetes Cluster with HAProxy on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fmrturkmen.com%2fposts%2finstall-ha-kubernetes-cluster%2f&title=Setup%20Highly%20Available%20Kubernetes%20Cluster%20with%20HAProxy"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Setup Highly Available Kubernetes Cluster with HAProxy on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fmrturkmen.com%2fposts%2finstall-ha-kubernetes-cluster%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Setup Highly Available Kubernetes Cluster with HAProxy on whatsapp" href="https://api.whatsapp.com/send?text=Setup%20Highly%20Available%20Kubernetes%20Cluster%20with%20HAProxy%20-%20https%3a%2f%2fmrturkmen.com%2fposts%2finstall-ha-kubernetes-cluster%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Setup Highly Available Kubernetes Cluster with HAProxy on telegram" href="https://telegram.me/share/url?text=Setup%20Highly%20Available%20Kubernetes%20Cluster%20with%20HAProxy&url=https%3a%2f%2fmrturkmen.com%2fposts%2finstall-ha-kubernetes-cluster%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://mrturkmen.com/>mrturkmen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>