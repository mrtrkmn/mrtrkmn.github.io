<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>haproxy-with-nginx: setting them up for k8s cluster | mrturkmen</title>
<meta name=keywords content="kubernetes,docker,pod,HAProxy,cluster,master,node,nginx,worker,ingress"><meta name=description content="NGINX Ingress Controller Setup"><meta name=author content="mrturkmen"><link rel=canonical href=https://mrturkmen.com/posts/setup-ingress-controller/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.35f3df538b68cb2996b90f96eb38b8970d3c40141cd5b359525d6e5a9bc4454a.css integrity="sha256-NfPfU4toyymWuQ+W6zi4lw08QBQc1bNZUl1uWpvERUo=" rel="preload stylesheet" as=style><link rel=icon href=https://mrturkmen.com/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://mrturkmen.com/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://mrturkmen.com/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://mrturkmen.com/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://mrturkmen.com/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://mrturkmen.com/posts/setup-ingress-controller/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://mrturkmen.com/posts/setup-ingress-controller/"><meta property="og:site_name" content="mrturkmen"><meta property="og:title" content="haproxy-with-nginx: setting them up for k8s cluster"><meta property="og:description" content="NGINX Ingress Controller Setup"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-07-10T16:35:03+00:00"><meta property="article:modified_time" content="2020-07-10T16:35:03+00:00"><meta property="article:tag" content="Kubernetes"><meta property="article:tag" content="Docker"><meta property="article:tag" content="Pod"><meta property="article:tag" content="HAProxy"><meta property="article:tag" content="Cluster"><meta property="article:tag" content="Master"><meta property="og:image" content="https://mrturkmen.com/resources/assets/images/github_actions.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://mrturkmen.com/resources/assets/images/github_actions.png"><meta name=twitter:title content="haproxy-with-nginx: setting them up for k8s cluster"><meta name=twitter:description content="NGINX Ingress Controller Setup"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://mrturkmen.com/posts/"},{"@type":"ListItem","position":2,"name":"haproxy-with-nginx: setting them up for k8s cluster","item":"https://mrturkmen.com/posts/setup-ingress-controller/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"haproxy-with-nginx: setting them up for k8s cluster","name":"haproxy-with-nginx: setting them up for k8s cluster","description":"NGINX Ingress Controller Setup","keywords":["kubernetes","docker","pod","HAProxy","cluster","master","node","nginx","worker","ingress"],"articleBody":"In recent post, which is Setup Highly Available Kubernetes Cluster with HAProxy , a highly available Kubernetes cluster is created. However, once I started to dig in and deploy some stuff to cluster, I realized that I am not able to connect any deployed application or services. For instance, when an web application is deployed using HAProxy load balancer (endpoint), and check from kubectl (on client side), its status is running. However, that application could not be reached from outside world although I re-patch an external IP address by following command\n$ kubectl patch svc -n -p '{\"spec\": {\"type\": \"LoadBalancer\", \"externalIPs\":[\"\"]}}' After some searching and reading, I realized that worker nodes require their own ingress controllers in order to forward traffic between them in case of load. I will be giving more information of how I fix the issue, however let’s learn some basic terms and general information about ingress controller.\nWhat is ingress controller ? The best and simple explanation to this question is coming from Kubernetes official documentation over here, as they are expressing that ;\nIngress exposes HTTP and HTTPS routes from outside the cluster to services within the cluster. Traffic routing is controlled by rules defined on the Ingress resource.\nAn Ingress controller is responsible for fulfilling the Ingress, usually with a load balancer, though it may also configure your edge router or additional frontend to help handle the traffic.\nWhenever you have services which are running inside a cluster and would like to access them, you need to setup ingress controller for that cluster. The missing part was having no ingress controller on worker nodes in my k8s cluster. Everything was working however there was no access to them from outside world, that’s why ingress controller should take place in cluster architecture.\nIn this post, I will go for NGINX ingress controller with its default setup, however there are plenty of different ingress controllers which you may go for. I might change NGINX to Traefik in future but it depends on requirements yet for now, I will go with nginx ingress controller. The reason is that, it is super easy to setup, super rich with different features, included Kubernetes official documentation and fulfill what I am expecting for now.\nUpdates to cluster Let’s briefly what I have explained in previous post;\nCreate VMs Setup SSH connection Use KubeSpray to deploy cluster Create HAProxy and establish SSH connection with all nodes. I have noticed that when deploying cluster, some add-ons should be enabled in order to use ingress controller from cluster with external HAProxy load balancer. Now, since cluster deployment was established with Ansible playbooks, it is not needed to setup everything from scratch. All modified configuration can be re-deployed without effecting any resource which is exists on cluster setup. It means that, I can enable required parts in configuration file and re-deploy cluster as I did on previous post.\nEnable ingress controller from inventory file inside KubeSpray\n$ vim inventory/mycluster/group_vars/k8s-cluster/addons.yml # Nginx ingress controller deployment ingress_nginx_enabled: false -\u003e true Once this configuration part is updated from existing KubeSpray configuration files, k8s cluster should be redeployed with same command in previous post\nAssumption : previous configured KubeSpray settings are used.\n$ ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml It will take a while and update all necessary parts which are required.\nInclude Ingress API object to route traffic from external HAProxy server to internal services\nTo include Ingress API object, HAProxy configuration file should be modified, following lines should be added to /etc/haproxy/haproxy.cfg file.\n$ vim /etc/haproxy/haproxy.cfg frontend kubernetes-ingress-http bind *:80 default_backend kubernetes-worker-nodes-http backend kubernetes-worker-nodes-http balance leastconn option tcp-check server worker1 10.0.128.81:80 check fall 3 rise 2 server worker2 10.0.128.137:80 check fall 3 rise 2 server worker3 10.0.128.156:80 check fall 3 rise 2 In given configuration balancing algorithm is leastconn which can be changed into any load balancer algorithm which is supported by HAProxy, however leastconn algorithm is fitting more to what I would like to achieve that’s why it is declared as leastconn. Note that this configuration addition is on top of added part on previous post.\nOnce HAProxy configuration is updated, HAProxy should be restarted systemctl restart haproxy. It is all for HAProxy configuration, now let’s dive into setting up NGINX Ingress Controller.\nSetup NGINX Ingress Controller It is super simple to deploy and setting up NGINX ingress controller since it is well documented and explains required parts in detail. To setup NGINX Ingress Controller, I will follow official guideline which is exists on NGINX Ingress Controller Installation.\nImage is taken from (https://www.nginx.com/products/nginx/kubernetes-ingress-controller/#resources)\nIn normal cases, the situation is as given figure above, however, since in existing k8s cluster, I am using HAProxy for communicating with clients, I need NGINX ingress controller inside worker nodes which will manage running applications/services by communicating with HAProxy and eventually, the services will be accessible from outside world.\nIf I summarize how overview diagram will look like in my case is like in given figure below.\nIt can be observed that, in given k8s cluster overview, HAProxy is in front, it communicates with clients, afterwards transmitting request based on defined rule on HAProxy configuration. Each worker node has NGINX ingress controller, what exactly it means, whenever a request appear to cluster, worker nodes will agree between each other and response back to user without having any problem. Since NGINX ingress controller is capable of load balancing inside worker nodes as well.\nThere is also Ingress Resource Rules part inside cluster, what it does, is that all routing rules based on path forwarded given service, an example on this is given below.\nSteps to create NGINX Ingress controller All steps shown below for installation of NGINX Ingress Controller taken from https://docs.nginx.com/nginx-ingress-controller/installation/\nMake sure that you are a client with administrator privilege, all steps related to NGINX ingress controller should be done through kubectl (on client computer/server)\nClone Ingress Controller Repo $ git clone https://github.com/nginxinc/kubernetes-ingress/ $ cd kubernetes-ingress Create a namespace and a service account for the Ingress controller $ kubectl apply -f common/ns-and-sa.yaml Create a cluster role and cluster role binding for the service account $ kubectl apply -f rbac/rbac.yaml Create a secret with a TLS certificate and a key for the default server in NGINX $ kubectl apply -f common/default-server-secret.yaml Create a config map for customizing NGINX configuration: $ kubectl apply -f common/nginx-config.yaml Afterwards, there are two different ways to run NGINX ingress controller deployment, which are as daemonset or as deployment. Main difference between those are summarized on official installation page as;\nUse a Deployment. When you run the Ingress Controller by using a Deployment, by default, Kubernetes will create one Ingress controller pod.\nUse a DaemonSet: When you run the Ingress Controller by using a DaemonSet, Kubernetes will create an Ingress controller pod on every node of the cluster.\nI will go with DaemonSet approach, the reason is that generally when you have background-ish tasks which will run non-stateless then DaemonSet is more preferred way of running it.\n$ kubectl apply -f daemon-set/nginx-ingress.yaml Once it is applied as daemon set, the result could be checked with following command and result will be similar to given result below.\n$ kubectl get all NAME READY STATUS RESTARTS AGE pod/nginx-ingress-47z8r 1/1 Running 0 24h pod/nginx-ingress-cmkfq 1/1 Running 0 24h pod/nginx-ingress-ft5pv 1/1 Running 0 24h pod/nginx-ingress-q554l 1/1 Running 0 24h pod/nginx-ingress-ssdrj 1/1 Running 0 24h pod/nginx-ingress-t9jml 1/1 Running 0 24h NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE daemonset.apps/nginx-ingress 6 6 6 6 6 24h Deploy Example Application To test how an application will be exposed to externally from k8s cluster, an example applicaton could be deployed as given below. Note that the following example is simplest example for this context, hence, keep in mind that it might require more configuration and detailed approach then described here when you would like to deploy more complex applications.\nCreate a sample NGINX Web Server (Using provided example) nginx-deploy-main.yml\napiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2 kind: Deployment metadata: name: nginx-deployment spec: selector: matchLabels: app: nginx replicas: 2 # tells deployment to run 2 pods matching the template template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 Taken from https://kubernetes.io/docs/tasks/run-application/run-stateless-application-deployment/\nIn given yaml deployment file above, two replicas of NGINX:1.14.2 will be deployed to cluster and it has name of nginx-deployment. The yaml explains itself very well.\nIt can be deployed either through directly from official link or from your local depends on your preferences.\n$ kubectl apply -f https://k8s.io/examples/application/deployment.yaml ## or you can do same thing with local file as given below $ kubectl apply -f nginx-deploy-main.yml Expose deployment:\n$ kubectl expose deploy nginx-deployment --port 80 Once it is deployed to cluster and exposed, there is one step left for this simple counter example is that, exposing the service and creating ingress rule (resource) in yaml file, by specifiying kind as Ingress.\napiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: name: nginx-ingress spec: rules: - host: (a domain like test.mydomain.com) http: paths: - path: / backend: serviceName: nginx-deployment servicePort: 80 The crucial part is serviceName and servicePort which are defining specifications of the services within cluster. The yaml specifications can be expanded as shown below, assume that you have wildcard record in your domain name server and have multiple services which are running in same port in a cluster, yaml file can be re-defined as given below.\nnginx-ingress-resource.yml\napiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: name: ingress-controller spec: rules: - host: (a domain like test.mydomain.com) http: paths: - path: / backend: serviceName: nginx-deployment servicePort: 80 - path: /apache backend: serviceName: apache-deployment servicePort: 80 - path: /native-web-server backend: serviceName: native-web-server-deployment servicePort: 80 Keep in mind that all given services should be deployed before hand otherwise when a request made to any path which is not deployed, it may return either 404 or 500. There are plenty of different options to define and update the components in a k8s cluster. Therefore, all yaml files should be changed according to requirements.\nCreate ingress controller rules from provided yaml file\n$ kubectl create -f nginx-ingress-resource.yml Now, the NGINX web server deployment is ready on given DNS record in yaml file and according to request paths different services can be called which are also running inside kubernetes cluster.\nNote that, provided yaml files are just simple example of deploying NGINX web server without any certification, when certificates (HTTPS) enabled or any other type of deployment happened different configurations should be applied.\nWhen everything goes without any problem, you will have a cluster which uses NGINX Ingress controller for internal cluster routing and HAProxy as communication endpoint for clients. Keep in mind that whenever a new service or deployment take place, required configuration should be enabled in HAProxy configuration as it is enabled for port 80 applications above. Different services will have different requirements therefore it is important to catch main logic in a setup. It is all done for this post.\nCheers !\n","wordCount":"1825","inLanguage":"en","image":"https://mrturkmen.com/resources/assets/images/github_actions.png","datePublished":"2020-07-10T16:35:03Z","dateModified":"2020-07-10T16:35:03Z","author":{"@type":"Person","name":"mrturkmen"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://mrturkmen.com/posts/setup-ingress-controller/"},"publisher":{"@type":"Organization","name":"mrturkmen","logo":{"@type":"ImageObject","url":"https://mrturkmen.com/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://mrturkmen.com/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://mrturkmen.com/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://mrturkmen.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://mrturkmen.com/>Home</a>&nbsp;»&nbsp;<a href=https://mrturkmen.com/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">haproxy-with-nginx: setting them up for k8s cluster</h1><div class=post-description>NGINX Ingress Controller Setup</div><div class=post-meta><span title='2020-07-10 16:35:03 +0000 UTC'>July 10, 2020</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;mrturkmen&nbsp;|&nbsp;<a href=https://github.com/mrtrkmn/mrtrkmn.github.io/edit/master/content/posts/setup-ingress-controller.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#what-is-ingress-controller- aria-label="What is ingress controller ?">What is ingress controller ?</a></li><li><a href=#updates-to-cluster aria-label="Updates to cluster">Updates to cluster</a><ul><li><a href=#setup-nginx-ingress-controller aria-label="Setup NGINX Ingress Controller">Setup NGINX Ingress Controller</a><ul><li><a href=#steps-to-create-nginx-ingress-controller aria-label="Steps to create NGINX Ingress controller">Steps to create NGINX Ingress controller</a></li></ul></li><li><a href=#deploy-example-application aria-label="Deploy Example Application">Deploy Example Application</a></li></ul></li></ul></div></details></div><div class=post-content><p>In recent post, which is <a href=https://mrturkmen.com/install-ha-kubernetes-cluster/>Setup Highly Available Kubernetes Cluster with HAProxy </a>, a highly available Kubernetes cluster is created. However, once I started to dig in and deploy some stuff to cluster, I realized that I am not able to connect any deployed application or services. For instance, when an web application is deployed using HAProxy load balancer (endpoint), and check from <code>kubectl</code> (on client side), its status is running. However, that application could not be reached from outside world although I re-patch an external IP address by following command</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span> $ kubectl patch svc &lt;application-name&gt; -n &lt;name-of-namespace&gt; -p <span style=color:#e6db74>&#39;{&#34;spec&#34;: {&#34;type&#34;: &#34;LoadBalancer&#34;, &#34;externalIPs&#34;:[&#34;&lt;haproxy-ip-address&gt;&#34;]}}&#39;</span> 
</span></span></code></pre></div><p>After some searching and reading, I realized that worker nodes require their own ingress controllers in order to forward traffic between them in case of load. I will be giving more information of how I fix the issue, however let&rsquo;s learn some basic terms and general information about ingress controller.</p><h1 id=what-is-ingress-controller->What is ingress controller ?<a hidden class=anchor aria-hidden=true href=#what-is-ingress-controller->#</a></h1><p>The best and simple explanation to this question is coming from Kubernetes official documentation over <a href=https://kubernetes.io/docs/concepts/services-networking/ingress/>here</a>, as they are expressing that ;</p><blockquote><p>Ingress exposes HTTP and HTTPS routes from outside the cluster to services within the cluster. Traffic routing is controlled by rules defined on the Ingress resource.</p></blockquote><blockquote><p>An <a href=https://kubernetes.io/docs/concepts/services-networking/ingress-controllers>Ingress controller</a> is responsible for fulfilling the Ingress, usually with a load balancer, though it may also configure your edge router or additional frontend to help handle the traffic.</p></blockquote><p>Whenever you have services which are running inside a cluster and would like to access them, you need to setup ingress controller for that cluster. The missing part was having no ingress controller on worker nodes in my k8s cluster. Everything was working however there was no access to them from outside world, that&rsquo;s why ingress controller should take place in cluster architecture.</p><p>In this post, I will go for <a href=https://kubernetes.github.io/ingress-nginx/>NGINX ingress controller</a> with its default setup, however there are plenty of different <a href=https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/#additional-controllers>ingress controllers</a> which you may go for. I might change NGINX to Traefik in future but it depends on requirements yet for now, I will go with nginx ingress controller. The reason is that, it is super easy to setup, super rich with different features, included Kubernetes official documentation and fulfill what I am expecting for now.</p><h1 id=updates-to-cluster>Updates to cluster<a hidden class=anchor aria-hidden=true href=#updates-to-cluster>#</a></h1><p>Let&rsquo;s briefly what I have explained in previous post;</p><ul><li>Create VMs</li><li>Setup SSH connection</li><li>Use KubeSpray to deploy cluster</li><li>Create HAProxy and establish SSH connection with all nodes.</li></ul><p>I have noticed that when deploying cluster, some add-ons should be enabled in order to use ingress controller from cluster with external HAProxy load balancer. Now, since cluster deployment was established with Ansible playbooks, it is not needed to setup everything from scratch. All modified configuration can be re-deployed without effecting any resource which is exists on cluster setup. It means that, I can enable required parts in configuration file and re-deploy cluster as I did on previous post.</p><ul><li><p><strong>Enable ingress controller from <a href=https://github.com/kubernetes-sigs/kubespray/blob/master/inventory/sample/group_vars/k8s-cluster/addons.yml>inventory</a> file inside KubeSpray</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ vim inventory/mycluster/group_vars/k8s-cluster/addons.yml
</span></span><span style=display:flex><span><span style=color:#75715e># Nginx ingress controller deployment</span>
</span></span><span style=display:flex><span>ingress_nginx_enabled: false -&gt; true
</span></span></code></pre></div><p>Once this configuration part is updated from existing KubeSpray configuration files, k8s cluster should be redeployed with same command in <a href=https://mrturkmen.com/install-ha-kubernetes-cluster/>previous post</a></p><p><em>Assumption</em> : previous configured KubeSpray settings are used.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ ansible-playbook -i inventory/mycluster/hosts.yaml  --become --become-user<span style=color:#f92672>=</span>root cluster.yml
</span></span></code></pre></div><p>It will take a while and update all necessary parts which are required.</p></li><li><p><strong>Include Ingress API object to route traffic from external HAProxy server to internal services</strong></p><p>To include Ingress API object, HAProxy configuration file should be modified, following lines should be added to <code>/etc/haproxy/haproxy.cfg</code> file.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ vim /etc/haproxy/haproxy.cfg
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    frontend kubernetes-ingress-http
</span></span><span style=display:flex><span>        bind *:80
</span></span><span style=display:flex><span>        default_backend kubernetes-worker-nodes-http
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    backend kubernetes-worker-nodes-http
</span></span><span style=display:flex><span>        balance leastconn
</span></span><span style=display:flex><span>        option tcp-check
</span></span><span style=display:flex><span>        server worker1 10.0.128.81:80 check fall <span style=color:#ae81ff>3</span> rise <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>        server worker2 10.0.128.137:80 check fall <span style=color:#ae81ff>3</span> rise <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>        server worker3 10.0.128.156:80 check fall <span style=color:#ae81ff>3</span> rise <span style=color:#ae81ff>2</span>
</span></span></code></pre></div><p>In given configuration balancing algorithm is <code>leastconn</code> which can be changed into any load balancer algorithm which is supported by HAProxy, however <code>leastconn</code> algorithm is fitting more to what I would like to achieve that&rsquo;s why it is declared as <code>leastconn</code>. Note that this configuration addition is on top of added part on <a href=https://mrturkmen.com/install-ha-kubernetes-cluster/>previous post</a>.</p><p>Once HAProxy configuration is updated, HAProxy should be restarted <code>systemctl restart haproxy</code>. It is all for HAProxy configuration, now let&rsquo;s dive into setting up NGINX Ingress Controller.</p></li></ul><h2 id=setup-nginx-ingress-controller>Setup NGINX Ingress Controller<a hidden class=anchor aria-hidden=true href=#setup-nginx-ingress-controller>#</a></h2><p>It is super simple to deploy and setting up NGINX ingress controller since it is well documented and explains required parts in detail. To setup NGINX Ingress Controller, I will follow official guideline which is exists on <a href=https://docs.nginx.com/nginx-ingress-controller/installation/>NGINX Ingress Controller Installation</a>.</p><p><img alt="NGINX INGRESS CONTROLLER" loading=lazy src=../../images/kubernetes/nginx-ingress-controller.png></p><p><em>Image is taken from (<a href=https://www.nginx.com/products/nginx/kubernetes-ingress-controller/#resources>https://www.nginx.com/products/nginx/kubernetes-ingress-controller/#resources</a>)</em></p><p>In normal cases, the situation is as given figure above, however, since in existing k8s cluster, I am using HAProxy for communicating with clients, I need NGINX ingress controller inside worker nodes which will manage running applications/services by communicating with HAProxy and eventually, the services will be accessible from outside world.</p><p>If I summarize how overview diagram will look like in my case is like in given figure below.</p><p><img alt="INGRESS CONTOLLERS OVERVIEW" loading=lazy src=../../images/kubernetes/overview-ingress-controller.png></p><p>It can be observed that, in given k8s cluster overview, HAProxy is in front, it communicates with clients, afterwards transmitting request based on defined rule on HAProxy configuration. Each worker node has NGINX ingress controller, what exactly it means, whenever a request appear to cluster, worker nodes will agree between each other and response back to user without having any problem. Since NGINX ingress controller is capable of load balancing inside worker nodes as well.</p><p>There is also Ingress Resource Rules part inside cluster, what it does, is that all routing rules based on path forwarded given service, an example on this is given below.</p><h3 id=steps-to-create-nginx-ingress-controller>Steps to create NGINX Ingress controller<a hidden class=anchor aria-hidden=true href=#steps-to-create-nginx-ingress-controller>#</a></h3><p><em>All steps shown below for installation of NGINX Ingress Controller taken from <a href=https://docs.nginx.com/nginx-ingress-controller/installation/>https://docs.nginx.com/nginx-ingress-controller/installation/</a></em></p><p><strong>Make sure that you are a client with administrator privilege, all steps related to NGINX ingress controller should be done through <code>kubectl</code> (on client computer/server)</strong></p><ul><li><strong>Clone Ingress Controller Repo</strong></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ git clone https://github.com/nginxinc/kubernetes-ingress/
</span></span><span style=display:flex><span>$ cd kubernetes-ingress
</span></span></code></pre></div><ul><li><strong>Create a namespace and a service account for the Ingress controller</strong></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl apply -f common/ns-and-sa.yaml
</span></span></code></pre></div><ul><li><strong>Create a cluster role and cluster role binding for the service account</strong></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl apply -f rbac/rbac.yaml
</span></span></code></pre></div><ul><li><strong>Create a secret with a TLS certificate and a key for the default server in NGINX</strong></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl apply -f common/default-server-secret.yaml
</span></span></code></pre></div><ul><li><strong>Create a config map for customizing NGINX configuration:</strong></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl apply -f common/nginx-config.yaml
</span></span></code></pre></div><p>Afterwards, there are two different ways to run NGINX ingress controller deployment, which are as daemonset or as deployment. Main difference between those are summarized on official <a href=https://docs.nginx.com/nginx-ingress-controller/installation/installation-with-manifests/>installation page</a> as;</p><blockquote><p>Use a Deployment. When you run the Ingress Controller by using a Deployment, by default, Kubernetes will create one Ingress controller pod.</p></blockquote><blockquote><p>Use a DaemonSet: When you run the Ingress Controller by using a DaemonSet, Kubernetes will create an Ingress controller pod on every node of the cluster.</p></blockquote><p>I will go with DaemonSet approach, the reason is that generally when you have background-ish tasks which will run non-stateless then DaemonSet is more preferred way of running it.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl apply -f daemon-set/nginx-ingress.yaml
</span></span></code></pre></div><p>Once it is applied as daemon set, the result could be checked with following command and result will be similar to given result below.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get all 
</span></span><span style=display:flex><span>NAME                      READY   STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>pod/nginx-ingress-47z8r   1/1     Running   <span style=color:#ae81ff>0</span>          24h
</span></span><span style=display:flex><span>pod/nginx-ingress-cmkfq   1/1     Running   <span style=color:#ae81ff>0</span>          24h
</span></span><span style=display:flex><span>pod/nginx-ingress-ft5pv   1/1     Running   <span style=color:#ae81ff>0</span>          24h
</span></span><span style=display:flex><span>pod/nginx-ingress-q554l   1/1     Running   <span style=color:#ae81ff>0</span>          24h
</span></span><span style=display:flex><span>pod/nginx-ingress-ssdrj   1/1     Running   <span style=color:#ae81ff>0</span>          24h
</span></span><span style=display:flex><span>pod/nginx-ingress-t9jml   1/1     Running   <span style=color:#ae81ff>0</span>          24h
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
</span></span><span style=display:flex><span>daemonset.apps/nginx-ingress   <span style=color:#ae81ff>6</span>         <span style=color:#ae81ff>6</span>         <span style=color:#ae81ff>6</span>       <span style=color:#ae81ff>6</span>            <span style=color:#ae81ff>6</span>           &lt;none&gt;          24h
</span></span></code></pre></div><h2 id=deploy-example-application>Deploy Example Application<a hidden class=anchor aria-hidden=true href=#deploy-example-application>#</a></h2><p>To test how an application will be exposed to externally from k8s cluster, an example applicaton could be deployed as given below. Note that the following example is simplest example for this context, hence, keep in mind that it might require more configuration and detailed approach then described here when you would like to deploy more complex applications.</p><ul><li><strong>Create a sample NGINX Web Server</strong> (Using provided example)</li></ul><p><em>nginx-deploy-main.yml</em></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>apps/v1</span> <span style=color:#75715e># for versions before 1.9.0 use apps/v1beta2</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Deployment</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>nginx-deployment</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>selector</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>matchLabels</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>app</span>: <span style=color:#ae81ff>nginx</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>replicas</span>: <span style=color:#ae81ff>2</span> <span style=color:#75715e># tells deployment to run 2 pods matching the template</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>template</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>app</span>: <span style=color:#ae81ff>nginx</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>containers</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>nginx</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>image</span>: <span style=color:#ae81ff>nginx:1.14.2</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>        - <span style=color:#f92672>containerPort</span>: <span style=color:#ae81ff>80</span>
</span></span></code></pre></div><p><em>Taken from <a href=https://kubernetes.io/docs/tasks/run-application/run-stateless-application-deployment/>https://kubernetes.io/docs/tasks/run-application/run-stateless-application-deployment/</a></em></p><p>In given yaml deployment file above, two replicas of NGINX:1.14.2 will be deployed to cluster and it has name of <code>nginx-deployment</code>. The yaml explains itself very well.</p><p>It can be deployed either through directly from official link or from your local depends on your preferences.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl apply -f https://k8s.io/examples/application/deployment.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## or you can do same thing with local file as given below</span>
</span></span><span style=display:flex><span>$ kubectl apply -f nginx-deploy-main.yml
</span></span></code></pre></div><p>Expose deployment:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl expose deploy nginx-deployment --port <span style=color:#ae81ff>80</span>
</span></span></code></pre></div><p>Once it is deployed to cluster and exposed, there is one step left for this simple counter example is that, exposing the service and creating ingress rule (resource) in yaml file, by specifiying kind as <code>Ingress</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>networking.k8s.io/v1beta1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Ingress</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>nginx-ingress</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>rules</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>host</span>: <span style=color:#ae81ff>&lt;dns-record&gt; (a domain like test.mydomain.com)</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>http</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>paths</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>path</span>: <span style=color:#ae81ff>/</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>backend</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>serviceName</span>: <span style=color:#ae81ff>nginx-deployment</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>servicePort</span>: <span style=color:#ae81ff>80</span>
</span></span></code></pre></div><p>The crucial part is <code>serviceName</code> and <code>servicePort</code> which are defining specifications of the services within cluster. The yaml specifications can be expanded as shown below, assume that you have wildcard record in your domain name server and have multiple services which are running in same port in a cluster, yaml file can be re-defined as given below.</p><p><em>nginx-ingress-resource.yml</em></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>networking.k8s.io/v1beta1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Ingress</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>ingress-controller</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>rules</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>host</span>: <span style=color:#ae81ff>&lt;dns-record&gt; (a domain like test.mydomain.com)</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>http</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>paths</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>path</span>: <span style=color:#ae81ff>/</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>backend</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>serviceName</span>: <span style=color:#ae81ff>nginx-deployment</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>servicePort</span>: <span style=color:#ae81ff>80</span>
</span></span><span style=display:flex><span>      - <span style=color:#f92672>path</span>: <span style=color:#ae81ff>/apache</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>backend</span>: 
</span></span><span style=display:flex><span>           <span style=color:#f92672>serviceName</span>: <span style=color:#ae81ff>apache-deployment</span>
</span></span><span style=display:flex><span>           <span style=color:#f92672>servicePort</span>: <span style=color:#ae81ff>80</span>
</span></span><span style=display:flex><span>      - <span style=color:#f92672>path</span>: <span style=color:#ae81ff>/native-web-server </span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>backend</span>:
</span></span><span style=display:flex><span>           <span style=color:#f92672>serviceName</span>: <span style=color:#ae81ff>native-web-server-deployment</span>
</span></span><span style=display:flex><span>           <span style=color:#f92672>servicePort</span>: <span style=color:#ae81ff>80</span>
</span></span></code></pre></div><p>Keep in mind that all given services should be deployed before hand otherwise when a request made to any path which is not deployed, it may return either 404 or 500. There are plenty of different options to define and update the components in a k8s cluster. Therefore, all yaml files should be changed according to requirements.</p><p><em>Create ingress controller rules from provided yaml file</em></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl create -f nginx-ingress-resource.yml
</span></span></code></pre></div><p>Now, the NGINX web server deployment is ready on given DNS record in yaml file and according to request paths different services can be called which are also running inside kubernetes cluster.</p><p><img alt="NGINX WEB SERVER DEPLOYMENT RESULT" loading=lazy src=../../images/kubernetes/nginx-web-server.png></p><p>Note that, provided yaml files are just simple example of deploying NGINX web server without any certification, when certificates (HTTPS) enabled or any other type of deployment happened different configurations should be applied.</p><p>When everything goes without any problem, you will have a cluster which uses NGINX Ingress controller for internal cluster routing and HAProxy as communication endpoint for clients. Keep in mind that whenever a new service or deployment take place, required configuration should be enabled in HAProxy configuration as it is enabled for port 80 applications above. Different services will have different requirements therefore it is important to catch main logic in a setup. It is all done for this post.</p><p>Cheers !</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://mrturkmen.com/tags/kubernetes/>Kubernetes</a></li><li><a href=https://mrturkmen.com/tags/docker/>Docker</a></li><li><a href=https://mrturkmen.com/tags/pod/>Pod</a></li><li><a href=https://mrturkmen.com/tags/haproxy/>HAProxy</a></li><li><a href=https://mrturkmen.com/tags/cluster/>Cluster</a></li><li><a href=https://mrturkmen.com/tags/master/>Master</a></li><li><a href=https://mrturkmen.com/tags/node/>Node</a></li><li><a href=https://mrturkmen.com/tags/nginx/>Nginx</a></li><li><a href=https://mrturkmen.com/tags/worker/>Worker</a></li><li><a href=https://mrturkmen.com/tags/ingress/>Ingress</a></li></ul><nav class=paginav><a class=prev href=https://mrturkmen.com/posts/grpc-calls-with-evans/><span class=title>« Prev</span><br><span>evans: universal gRPC client demonstration</span>
</a><a class=next href=https://mrturkmen.com/posts/install-ha-kubernetes-cluster/><span class=title>Next »</span><br><span>haproxy: setting it up for highly available k8s cluster</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share haproxy-with-nginx: setting them up for k8s cluster on x" href="https://x.com/intent/tweet/?text=haproxy-with-nginx%3a%20setting%20them%20up%20for%20k8s%20cluster&amp;url=https%3a%2f%2fmrturkmen.com%2fposts%2fsetup-ingress-controller%2f&amp;hashtags=kubernetes%2cdocker%2cpod%2cHAProxy%2ccluster%2cmaster%2cnode%2cnginx%2cworker%2cingress"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share haproxy-with-nginx: setting them up for k8s cluster on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fmrturkmen.com%2fposts%2fsetup-ingress-controller%2f&amp;title=haproxy-with-nginx%3a%20setting%20them%20up%20for%20k8s%20cluster&amp;summary=haproxy-with-nginx%3a%20setting%20them%20up%20for%20k8s%20cluster&amp;source=https%3a%2f%2fmrturkmen.com%2fposts%2fsetup-ingress-controller%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share haproxy-with-nginx: setting them up for k8s cluster on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fmrturkmen.com%2fposts%2fsetup-ingress-controller%2f&title=haproxy-with-nginx%3a%20setting%20them%20up%20for%20k8s%20cluster"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share haproxy-with-nginx: setting them up for k8s cluster on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fmrturkmen.com%2fposts%2fsetup-ingress-controller%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share haproxy-with-nginx: setting them up for k8s cluster on whatsapp" href="https://api.whatsapp.com/send?text=haproxy-with-nginx%3a%20setting%20them%20up%20for%20k8s%20cluster%20-%20https%3a%2f%2fmrturkmen.com%2fposts%2fsetup-ingress-controller%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share haproxy-with-nginx: setting them up for k8s cluster on telegram" href="https://telegram.me/share/url?text=haproxy-with-nginx%3a%20setting%20them%20up%20for%20k8s%20cluster&amp;url=https%3a%2f%2fmrturkmen.com%2fposts%2fsetup-ingress-controller%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share haproxy-with-nginx: setting them up for k8s cluster on ycombinator" href="https://news.ycombinator.com/submitlink?t=haproxy-with-nginx%3a%20setting%20them%20up%20for%20k8s%20cluster&u=https%3a%2f%2fmrturkmen.com%2fposts%2fsetup-ingress-controller%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://mrturkmen.com/>mrturkmen</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script defer src=https://static.cloudflareinsights.com/beacon.min.js data-cf-beacon='{"token": "866620f03a6a4a5d9b8e6cd46edf203e"}'></script></body></html>